{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba43649-7cbc-4d14-bfbc-37e69709fa96",
   "metadata": {},
   "source": [
    "# Lecture 10-3\n",
    "\n",
    "# Messing around with LLMs with Haystack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613ee3b-3e9f-40aa-8c74-45df3785eee5",
   "metadata": {},
   "source": [
    "Step 0: Get OpenAI API Key\n",
    "\n",
    "To get an OpenAI API key, you need to sign up for an OpenAI account and subscribe to their API service. \n",
    "\n",
    "- Go to the OpenAI developer website. https://platform.openai.com/\n",
    "- Click on \"Sign Up\" to create a new account, or \"Log In\" if you already have an account.\n",
    "- Click on the Settings Gear. \n",
    "- Navigate to \"API Keys\" \n",
    "- You may need to set up a billing plan. If you stick with gpt 3.5, it is cheap. You can buy $5 of credits, which will be more than enough for experimentation.\n",
    "- Go to the API keys section of your OpenAI account.\n",
    "- Click on \"Create new secret key\" to generate a new API key.\n",
    "- Copy the generated API key.\n",
    "- Create a `.env` file in your project directory.\n",
    "- In the `.env` file, enter:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=text_of_super_secret_api_key\n",
    "```\n",
    "\n",
    "- You won't be able to see the api key again once you close the dialog. If you don't store it and lose it, you'll need to create a new API key.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ba30a-7ff2-478b-8765-6a88c54df695",
   "metadata": {},
   "source": [
    "Step 1: Create a New Virtual Environment\n",
    "\n",
    "- Open your terminal\n",
    "- Create a new virtual environment and activate it:\n",
    "\n",
    "```\n",
    "python -m venv haystackai\n",
    "haystackai\\Scripts\\activate\n",
    "```\n",
    "\n",
    "just remember to deactivate your virtual environment at the end\n",
    "\n",
    "```\n",
    "deactivate\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521b14b1-54d0-490f-8f15-7f7eedcc8e5b",
   "metadata": {},
   "source": [
    "See: https://haystack.deepset.ai/tutorials/27_first_rag_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b389a88-a0c0-4b57-8faf-ef8bb9924800",
   "metadata": {},
   "source": [
    "Once you've activated the haystack environment, install Jupyter, Haystack, and other necessary packages in your Conda environment:\n",
    "\n",
    "```\n",
    "pip install openai python-dotenv\n",
    "pip install torch\n",
    "pip install haystack-ai\n",
    "pip install \"datasets>=2.6.1\"\n",
    "pip install \"sentence-transformers>=2.2.0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b7e83-7102-4dfe-85b9-1685a9f06d2f",
   "metadata": {},
   "source": [
    "Open the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e88c5a3-388a-44e5-9f35-1fbb2603a246",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'haystack'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# cell 1: let's haystack know you are running a tutorial\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtelemetry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tutorial_running\n\u001b[0;32m      4\u001b[0m tutorial_running(\u001b[38;5;241m27\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'haystack'"
     ]
    }
   ],
   "source": [
    "# cell 1: let's haystack know you are running a tutorial\n",
    "from haystack.telemetry import tutorial_running\n",
    "\n",
    "tutorial_running(27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99addb33-1a15-491e-9555-fef0bc709362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfdd37d-aeeb-44bf-9ba7-e3b79687be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f91c87-9ecf-40d9-bc40-cb9df0c56803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_embedder.warm_up()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabde90c-51e5-49d0-94bd-790168b13369",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ca751d-ef20-4a7f-a74f-ffea08bdf731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9d468f-ba96-459b-9e20-85652003abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "\n",
    "retriever = InMemoryEmbeddingRetriever(document_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36489bc7-2c46-4e4c-ae3e-f6ab9dc06242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "template = \"\"\"\n",
    "Given the following information, answer the question.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333de27-ecd9-4f98-93bc-af3b73770d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "from getpass import getpass\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")\n",
    "generator = OpenAIGenerator(model=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8556bdc-7637-469f-bbcd-04ea0ef8670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "basic_rag_pipeline = Pipeline()\n",
    "# Add components to your pipeline\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"llm\", generator)\n",
    "\n",
    "# Now, connect the components to each other\n",
    "basic_rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "basic_rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "basic_rag_pipeline.connect(\"prompt_builder\", \"llm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4693522-265d-4e3b-92b1-6956d81e70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What does Rhodes Statue look like?\"\n",
    "\n",
    "response = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
    "\n",
    "print(response[\"llm\"][\"replies\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724ab18b-6606-40dc-a52a-8ec0543333ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did construction for the Rhodes statue begin?\"\n",
    "\n",
    "response = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
    "\n",
    "print(response[\"llm\"][\"replies\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275fe483-68e2-4640-a557-9140e2a4853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"Where is Gardens of Babylon?\",\n",
    "    \"Why did people build Great Pyramid of Giza?\",\n",
    "    \"What is UCLA?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c08d5-f0c3-4739-b11d-4e512c33c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in examples:\n",
    "    print(question)\n",
    "    response = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
    "    print(response[\"llm\"][\"replies\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c714f6-919f-4067-876e-067695a37c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
